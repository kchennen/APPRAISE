{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "AlphaFold2PredictStructure.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kchennen/APPRAISE/blob/master/AlphaFold2PredictStructure.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G4yBrceuFbf3"
      },
      "source": [
        "#Protein structure prediction with AlphaFold2 and MMseqs2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UGUBLzB3C6WN"
      },
      "source": [
        "\n",
        "Easy to use version of AlphaFold 2 (Jumper et al. 2021, Nature) using an API hosted at the Södinglab based on the MMseqs2 server (Mirdita et al. 2019, Bioinformatics) for the multiple sequence alignment creation. \n",
        "\n",
        "**Quickstart**\n",
        "1. Change the runtime type to GPU at \"Runtime\" -> \"Change runtime type\" (improves speed)\n",
        "2. Paste your protein sequence in the input field below\n",
        "3. Press \"Runtime\" -> \"Run all\"\n",
        "4. The pipeline has 8 steps. The currently running steps is indicated by a circle with a stop sign next to it. \n",
        "\n",
        "**Result**\n",
        "\n",
        "We produce two result files (1) a PDB formated structure and (2) a plot of the model quality. At the end of the computation a download modal box will pop with a `result.tar.gz` file.\n",
        "\n",
        "**Troubleshooting**\n",
        "* Try to restart the session \"Runntime\" -> \"Factory reset runtime\"\n",
        "* Check your input sequence \n",
        "\n",
        "\n",
        "**Limitations**\n",
        "* MSAs: MMseqs2 might not find as many hits compared to HHblits/HMMer searched against BFD and Mgnify.\n",
        "* Templates: Currently we do not use template information. But this is work in progress. \n",
        "* Computing resources: MMseqs2 is fast and we can probably handle >20k requests per day but it is not limitless. \n",
        "* It uses only one AF2 model followed by Amber Relaxation.\n",
        "\n",
        "For best results, we recommend using the full pipeline: https://github.com/deepmind/alphafold\n",
        "\n",
        "Most of the python code was written by Sergey Ovchinnikov (@sokrypton). The API is hosted at the Södinglab (@SoedingL) and maintained by Milot Mirdita (@milot_mirdita). Martin Steinegger (@thesteinegger) integrated everything.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kOblAo-xetgx",
        "cellView": "form"
      },
      "source": [
        "#@title Input protein sequence here before you \"Run all\"\n",
        "\n",
        "protein = 'MLILISPAKTLDYQSPLTTTRYTLPELLDNSQQLIHEARKLTPPQISTLMRISDKLAGINAARFHDWQPDFTPANARQAILAFKGDVYTGLQAETFSEDDFDFAQQHLRMLSGLYGVLRPLDLMQPYRLEMGIRLENARGKDLYQFWGDIITNKLNEALAAQGDNVVINLASDEYFKSVKPKKLNAEIIKPVFLDEKNGKFKIISFYAKKARGLMSRFIIENRLTKPEQLTGFNSEGYFFDEDSSSNGELVFKRYEQR' #@param {type:\"string\"}\n",
        "# remove whitespaces\n",
        "protein=protein.join(protein.split())\n",
        "with open(\"q.fasta\", \"w\") as text_file:\n",
        "    text_file.write(\">1\\n%s\" % protein)\n",
        "jobname = 'default' #@param {type:\"string\"}\n",
        "# remove whitespaces\n",
        "jobname=\"\".join(jobname.split())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iccGdbe_Pmt9",
        "cellView": "form"
      },
      "source": [
        "#@title Install dependencies\n",
        "%%bash\n",
        "if [ -e AF2_READY ]; then\n",
        "  exit 0\n",
        "fi\n",
        "# install dependencies\n",
        "apt-get -qq -y update 2>&1 1>/dev/null\n",
        "apt-get -qq -y install jq curl zlib1g gawk 2>&1 1>/dev/null\n",
        "\n",
        "pip -q install biopython 2>&1 1>/dev/null\n",
        "pip -q install dm-haiku 2>&1 1>/dev/null\n",
        "pip -q install ml-collections 2>&1 1>/dev/null\n",
        "pip -q install mock 2>&1 1>/dev/null\n",
        "pip -q install py3Dmol 2>&1 1>/dev/null\n",
        "\n",
        "# download model\n",
        "git clone https://github.com/deepmind/alphafold.git --quiet\n",
        "mv alphafold alphafold_\n",
        "mv alphafold_/alphafold .\n",
        "\n",
        "# download model params (~1 min)\n",
        "wget -qnc https://storage.googleapis.com/alphafold/alphafold_params_2021-07-14.tar\n",
        "mkdir params\n",
        "tar -xf alphafold_params_2021-07-14.tar -C params/\n",
        "rm alphafold_params_2021-07-14.tar\n",
        "\n",
        "# install openmm for refinement\n",
        "wget -qnc https://git.scicore.unibas.ch/schwede/openstructure/-/raw/7102c63615b64735c4941278d92b554ec94415f8/modules/mol/alg/src/stereo_chemical_props.txt\n",
        "mv stereo_chemical_props.txt alphafold/common/\n",
        "wget -qnc https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh\n",
        "bash Miniconda3-latest-Linux-x86_64.sh -bfp /usr/local 2>&1 1>/dev/null\n",
        "conda install -y -q -c conda-forge openmm=7.5.1 python=3.7 pdbfixer 2>&1 1>/dev/null\n",
        "(cd /usr/local/lib/python3.7/site-packages; patch -s -p0 < /content/alphafold_/docker/openmm.patch)\n",
        "\n",
        "touch AF2_READY"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A9tUpDaikPC8",
        "cellView": "form"
      },
      "source": [
        "#@title Build MSA\n",
        "\n",
        "%%bash\n",
        "# build msa using the MMseqs2 search server\n",
        "ID=$(curl -s -F q=@q.fasta -F mode=all https://a3m.mmseqs.com/ticket/msa | jq -r '.id')\n",
        "STATUS=$(curl -s https://a3m.mmseqs.com/ticket/${ID} | jq -r '.status')\n",
        "while [ \"${STATUS}\" == \"RUNNING\" ]; do\n",
        "    STATUS=$(curl -s https://a3m.mmseqs.com/ticket/${ID} | jq -r '.status')\n",
        "    sleep 1\n",
        "done\n",
        "if [ \"${STATUS}\" == \"COMPLETE\" ]; then\n",
        "    curl -s https://a3m.mmseqs.com/result/download/${ID}  > result.tar.gz\n",
        "    tar xzf result.tar.gz\n",
        "    tr -d '\\000' < uniref.a3m > query.a3m\n",
        "else\n",
        "    echo \"MMseqs2 server did not return a valid result.\"\n",
        "    exit 1\n",
        "fi\n",
        "echo \"Found $(grep -c \">\" query.a3m) sequences (after redundacy filtering)\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JPWfhGssZdTb",
        "cellView": "form"
      },
      "source": [
        "#@title Setup model\n",
        "\n",
        "# the following code is written by Sergey Ovchinnikov\n",
        "# setup the model\n",
        "import os\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pickle\n",
        "import py3Dmol\n",
        "import matplotlib.pyplot as plt\n",
        "import sys\n",
        "sys.path.insert(0, '/usr/local/lib/python3.7/site-packages/')\n",
        "from alphafold.common import protein\n",
        "from alphafold.data import pipeline\n",
        "from alphafold.data import templates\n",
        "from alphafold.model import data\n",
        "from alphafold.model import config\n",
        "from alphafold.model import model\n",
        "from alphafold.relax import relax\n",
        "tf.get_logger().setLevel('ERROR')\n",
        "model_runners = {}\n",
        "models = [\"model_1\"] #,\"model_2\",\"model_3\",\"model_4\",\"model_5\"]\n",
        "for model_name in models:\n",
        "  model_config = config.model_config(model_name)\n",
        "  model_config.data.eval.num_ensemble = 1\n",
        "  model_params = data.get_model_haiku_params(model_name=model_name, data_dir=\".\")\n",
        "  model_runner = model.RunModel(model_config, model_params)\n",
        "  model_runners[model_name] = model_runner\n",
        "\n",
        "def mk_mock_template(query_sequence):\n",
        "  # since alphafold's model requires a template input\n",
        "  # we create a blank example w/ zero input, confidence -1\n",
        "  ln = len(query_sequence)\n",
        "  output_templates_sequence = \"-\"*ln\n",
        "  output_confidence_scores = np.full(ln,-1)\n",
        "  templates_all_atom_positions = np.zeros((ln, templates.residue_constants.atom_type_num, 3))\n",
        "  templates_all_atom_masks = np.zeros((ln, templates.residue_constants.atom_type_num))\n",
        "  templates_aatype = templates.residue_constants.sequence_to_onehot(output_templates_sequence,\n",
        "                                                                    templates.residue_constants.HHBLITS_AA_TO_ID)\n",
        "  template_features = {'template_all_atom_positions': templates_all_atom_positions[None],\n",
        "                       'template_all_atom_masks': templates_all_atom_masks[None],\n",
        "                       'template_sequence': [f'none'.encode()],\n",
        "                       'template_aatype': np.array(templates_aatype)[None],\n",
        "                       'template_confidence_scores': output_confidence_scores[None],\n",
        "                       'template_domain_names': [f'none'.encode()],\n",
        "                       'template_release_date': [f'none'.encode()]}\n",
        "  return template_features\n",
        "\n",
        "def predict_structure(prefix, feature_dict, model_runners, do_relax=True, random_seed=0):  \n",
        "  \"\"\"Predicts structure using AlphaFold for the given sequence.\"\"\"\n",
        "\n",
        "  # Run the models.\n",
        "  plddts = {}\n",
        "  for model_name, model_runner in model_runners.items():\n",
        "    processed_feature_dict = model_runner.process_features(feature_dict, random_seed=random_seed)\n",
        "    prediction_result = model_runner.predict(processed_feature_dict)\n",
        "    unrelaxed_protein = protein.from_prediction(processed_feature_dict,prediction_result)\n",
        "    unrelaxed_pdb_path = f'{prefix}_unrelaxed_{model_name}.pdb'\n",
        "    plddts[model_name] = prediction_result['plddt']\n",
        "\n",
        "    print(f\"{model_name} {plddts[model_name].mean()}\")\n",
        "\n",
        "    with open(unrelaxed_pdb_path, 'w') as f:\n",
        "      f.write(protein.to_pdb(unrelaxed_protein))\n",
        "\n",
        "    if do_relax:\n",
        "      # Relax the prediction.\n",
        "      amber_relaxer = relax.AmberRelaxation(max_iterations=0,tolerance=2.39,\n",
        "                                            stiffness=10.0,exclude_residues=[],\n",
        "                                            max_outer_iterations=20)      \n",
        "      relaxed_pdb_str, _, _ = amber_relaxer.process(prot=unrelaxed_protein)\n",
        "      relaxed_pdb_path = f'{prefix}_relaxed_{model_name}.pdb'\n",
        "      with open(relaxed_pdb_path, 'w') as f: f.write(relaxed_pdb_str)\n",
        "\n",
        "  return plddts"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hUYApPElB30u",
        "cellView": "form"
      },
      "source": [
        "#@title Predict structure\n",
        "a3m_lines = \"\".join(open(\"query.a3m\",\"r\").readlines())\n",
        "msa, deletion_matrix = pipeline.parsers.parse_a3m(a3m_lines)\n",
        "query_sequence = msa[0]\n",
        "\n",
        "feature_dict = {\n",
        "    **pipeline.make_sequence_features(sequence=query_sequence,\n",
        "                                      description=\"none\",\n",
        "                                      num_res=len(query_sequence)),\n",
        "    **pipeline.make_msa_features(msas=[msa],deletion_matrices=[deletion_matrix]),\n",
        "    **mk_mock_template(query_sequence)\n",
        "}\n",
        "plddts = predict_structure(jobname,feature_dict,model_runners)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "exKwNxDxF7IO",
        "cellView": "form"
      },
      "source": [
        "#@title Plot LDDT per residue\n",
        "# confidence per position\n",
        "plt.figure(dpi=100)\n",
        "for model,value in plddts.items():\n",
        "  plt.plot(value,label=model)\n",
        "plt.legend()\n",
        "plt.ylim(0,100)\n",
        "plt.ylabel(\"predicted LDDT\")\n",
        "plt.xlabel(\"positions\")\n",
        "plt.show()\n",
        "plt.savefig(jobname+\"_relaxed_model_1.png\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6xbvRNrwnJqj",
        "cellView": "form"
      },
      "source": [
        "#@title Show 3D structure\n",
        "p = py3Dmol.view(js='https://3dmol.org/build/3Dmol.js')\n",
        "p.addModel(open(jobname+\"_relaxed_model_1.pdb\",'r').read(),'pdb')\n",
        "p.setStyle({'cartoon': {'color':'spectrum'}})\n",
        "p.zoomTo()\n",
        "p.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "33g5IIegij5R",
        "cellView": "form"
      },
      "source": [
        "#@title Download result\n",
        "!tar cfz result.tar.gz $jobname\"_relaxed_model_1.pdb\" $jobname\"_relaxed_model_1.png\"\n",
        "from google.colab import files\n",
        "files.download('result.tar.gz')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}